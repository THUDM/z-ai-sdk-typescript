import { BaseRequestOptions, Usage, ToolCall, Tool } from './shared';

/**
 * The role of the message author
 */
export type ChatRole = 'system' | 'user' | 'assistant' | 'function' | 'tool';

/**
 * A message in a chat conversation
 */
export interface ChatMessage {
  /**
   * The role of the message author
   */
  role: ChatRole;
  
  /**
   * The contents of the message
   */
  content: string | null;
  
  /**
   * The name of the author of this message (optional)
   */
  name?: string;
  
  /**
   * The tool calls generated by the model
   */
  tool_calls?: ToolCall[];
  
  /**
   * Tool call that this message is responding to
   */
  tool_call_id?: string;
}

/**
 * Parameters for creating a chat completion
 */
export interface ChatCompletionCreateParams extends BaseRequestOptions {
  /**
   * ID of the model to use
   */
  model: string;
  
  /**
   * A list of messages comprising the conversation so far
   */
  messages: ChatMessage[];
  
  /**
   * An optional unique identifier representing your end-user
   */
  user?: string;
  
  /**
   * Whether to return a stream of partial results
   */
  stream?: boolean;
  
  /**
   * What sampling temperature to use, between 0 and 2
   */
  temperature?: number;
  
  /**
   * An alternative to sampling with temperature, called nucleus sampling
   */
  top_p?: number;
  
  /**
   * The maximum number of tokens to generate
   */
  max_tokens?: number;
  
  /**
   * Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far
   */
  presence_penalty?: number;
  
  /**
   * Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far
   */
  frequency_penalty?: number;
  
  /**
   * Up to 4 sequences where the API will stop generating further tokens
   */
  stop?: string | string[];
  
  /**
   * A list of tools the model may call
   */
  tools?: Tool[];
  
  /**
   * Controls which (if any) function is called by the model
   */
  tool_choice?: 'none' | 'auto' | string;
  
  /**
   * This feature is in Beta. If specified, our system will make a best effort to sample deterministically
   */
  seed?: number;
  
  /**
   * Whether to enable sampling
   */
  do_sample?: boolean;
  
  /**
   * Unique identifier for the request
   */
  request_id?: string;
  
  /**
   * Sensitive word check configuration
   */
  sensitive_word_check?: Record<string, any>;
}

/**
 * A choice in a chat completion response
 */
export interface ChatCompletionChoice {
  /**
   * The index of the choice in the list of choices
   */
  index: number;
  
  /**
   * The reason the model stopped generating tokens
   */
  finish_reason: 'stop' | 'length' | 'tool_calls' | 'content_filter' | null;
  
  /**
   * A chat completion message generated by the model
   */
  message: ChatMessage;
  
  /**
   * A chat completion delta generated by the model (for streaming)
   */
  delta?: Partial<ChatMessage>;
}

/**
 * Represents a chat completion response
 */
export interface ChatCompletion {
  /**
   * A unique identifier for the chat completion
   */
  id: string;
  
  /**
   * The object type, which is always "chat.completion"
   */
  object: 'chat.completion';
  
  /**
   * The Unix timestamp (in seconds) of when the chat completion was created
   */
  created: number;
  
  /**
   * The model used for the chat completion
   */
  model: string;
  
  /**
   * A list of chat completion choices
   */
  choices: ChatCompletionChoice[];
  
  /**
   * Usage statistics for the completion request
   */
  usage?: Usage;
}

/**
 * Represents a streamed chunk of a chat completion response
 */
export interface ChatCompletionChunk {
  /**
   * A unique identifier for the chat completion
   */
  id: string;
  
  /**
   * The object type, which is always "chat.completion.chunk"
   */
  object: 'chat.completion.chunk';
  
  /**
   * The Unix timestamp (in seconds) of when the chat completion was created
   */
  created: number;
  
  /**
   * The model used for the chat completion
   */
  model: string;
  
  /**
   * A list of chat completion choices
   */
  choices: ChatCompletionChoice[];
}